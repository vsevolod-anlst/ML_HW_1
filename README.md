# ML_HW_1
Скрины запушенного сервиса с ответами.

![1](https://github.com/vsevolod-anlst/ML_HW_1/assets/135347017/d00e50b6-2fe8-4311-ab40-ad8f4449e98b)
![2](https://github.com/vsevolod-anlst/ML_HW_1/assets/135347017/7005fc51-7b31-40f0-9d8a-a316d79e09a4)

Выводы:
Было сделано:
1. Исследованы полученные ДФ - тест и трейн
2. Произведена предобработка данных - заполнены пропуски, удалены единицы измерения, удалены дубликаты, 
3. Построены графики порпарного распределения и выявлены зависимые параметры. (какие именно - в файле ipynb, как и просиловь в домашке), график тепловой карты корреляции.
4. Обучена модель на вещественных признаках, результат предсказания r_2 = 0.594
5. Произведена стандартизация числовых признаков, и снова обучена модель, после чего качество предсказания ухудшилось r_2 = 0.565
6. Выявлен наиболее влияющий на предикт признак и это максимальная мощность
7. На стандартизированных числовых признаказ обучена Лассо-регрессия, результат предсказания r_2 =0.565
8. С помощью Грид найден наилучший коэф регуляризации для Лассо регресии, это alpha=26609, и произведено новое обучение, после чего результат предсказания ЕЩЕ снизился до r_2=0.533
9.С помощью Грид найдены наилучшие парамтеры для Эластик регресии, это alpha=15 и l1_ratio = 0.99, и произведено новое обучение, после чего результат предсказания стал r_2=0.532
10. Закодированны категориальные фичи и кол-во мест, после чего на полных данных с помощью Грид найден лучший параметр alpha=8.946, снова обучена модель с этим лучшим параметром и предсказание НАКОНЕЦто улучшилось до r_2=0.645.
11. Посчитана бизнесс-метрика того, в какой доле случаев модель в предсказании ошибается незначительно и это 0.246 от всех объектов теста, значит по остальным модель ошиблась более сильно, и в целом это не очень хороший результат...
12. Реализован сервис.

Результаты - наилучшие предсказания модель дает тогда, когда я обучаю ее и на числовых и на категориальных фичах, которые предварительно подверглись предобработке, нормализации и OneHot кодированию.
Наилучший буст качества мождели как раз дала OneHot кодирование совмещенное с нормированными числовыми признаками.

Не не вышло, но было сложно очень во всяких преобразованиях словарей в df, объектов Item в df... суммарно на работу потрачено гдето 50 часов.. в основоном из за вот этих какжется более легких вещей, чем само обучение....

У меня не вышло (я не понял как) сохранить в pickle коэфициэнты скаляризации.
Коэфициэнты моделы - вышло, но я не понял зачем мы это делали, ибо я в pickle сохраняю прям обученную модельку и pipline весь, и использую его в сервисе. Зачем нужны отдельно эти коэфициенты?
